# modules/asr/asr_service.py
import os
import torch
from modelscope.pipelines import pipeline
from modelscope.utils.constant import Tasks


class ASRService:
    def __init__(self,
                 model_name_or_path="damo/speech_funasr_asr_conformer_tiny",
                 cache_dir="/dev/nvme0n1p8/modelscope/funasr",
                 device="cuda" if torch.cuda.is_available() else "cpu"):
        """
        ä½¿ç”¨ ModelScope å®˜æ–¹ FunASR æ¨¡å‹è¿›è¡Œè¯­éŸ³è¯†åˆ«ã€‚
        æ¨¡å‹ä¼šè‡ªåŠ¨ä¸‹è½½åˆ°æŒ‡å®š cache_dirã€‚
        """
        self.model_name_or_path = model_name_or_path
        self.cache_dir = cache_dir
        self.device = device

        os.makedirs(cache_dir, exist_ok=True)
        os.environ["MODELSCOPE_CACHE"] = cache_dir

        print(f"ğŸ–¥ï¸ ä½¿ç”¨è®¾å¤‡: {self.device}")
        print(f"ğŸ“¦ æ¨¡å‹è·¯å¾„/åç§°: {self.model_name_or_path}")
        print(f"ğŸ’¾ ç¼“å­˜ç›®å½•: {self.cache_dir}")

        # åˆå§‹åŒ– ASR pipeline
        self.asr_pipeline = pipeline(
            task=Tasks.auto_speech_recognition,
            model=self.model_name_or_path,
            device=self.device,
            cache_dir=self.cache_dir
        )

    def transcribe(self, audio_path: str) -> str:
        """å¯¹éŸ³é¢‘æ–‡ä»¶è¿›è¡Œè¯†åˆ«"""
        if not os.path.exists(audio_path):
            raise FileNotFoundError(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
        print(f"ğŸ§ æ­£åœ¨è¯†åˆ«éŸ³é¢‘: {audio_path}")
        result = self.asr_pipeline(audio_in=audio_path)
        text = result.get("text", "")
        print(f"ğŸ“ è¯†åˆ«ç»“æœ: {text}")
        return text


