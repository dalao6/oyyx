# modules/retrieval/image_retrieval.py
import os
import logging
import torch
from PIL import Image
import numpy as np

# ç¡®ä¿ open_clip å·²å®‰è£…
import open_clip

# -----------------------------
# æ—¥å¿—é…ç½®
# -----------------------------
logger = logging.getLogger("ImageRetrieval")
if not logger.handlers:
    handler = logging.StreamHandler()
    formatter = logging.Formatter("%(asctime)s [%(levelname)s] %(message)s")
    handler.setFormatter(formatter)
    logger.addHandler(handler)
    logger.setLevel(logging.INFO)


class ImageRetrieval:
    def __init__(self, image_dir: str, model_path: str, device: str = "cuda"):
        self.image_dir = image_dir
        self.model_path = model_path
        self.device = device if torch.cuda.is_available() else "cpu"

        self.model = None
        self.preprocess = None
        self.image_embeddings = {}
        self.image_paths = []

        self._load_model()
        self._index_images()

    def _load_model(self):
        try:
            logger.info(f"[ImageRetrieval] ğŸš€ ä½¿ç”¨è®¾å¤‡: {self.device}")
            outputs = open_clip.create_model_and_transforms(
                "ViT-B-32", pretrained=self.model_path, device=self.device
            )
            if len(outputs) == 3:
                self.model, _, self.preprocess = outputs
            else:
                self.model, self.preprocess = outputs
            self.model.eval()
            logger.info(f"[ImageRetrieval] âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {self.model_path}")
        except RuntimeError as e:
            if "out of memory" in str(e).lower():
                logger.warning(
                    f"[ImageRetrieval] âš ï¸ CUDA æ˜¾å­˜ä¸è¶³ï¼Œè‡ªåŠ¨åˆ‡æ¢ä¸º CPU æ¨¡å¼: {e}"
                )
                self.device = "cpu"
                torch.cuda.empty_cache()
                outputs = open_clip.create_model_and_transforms(
                    "ViT-B-32", pretrained=self.model_path, device=self.device
                )
                if len(outputs) == 3:
                    self.model, _, self.preprocess = outputs
                else:
                    self.model, self.preprocess = outputs
                self.model.eval()
            else:
                logger.error(f"[ImageRetrieval] âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
                raise e

    def _index_images(self):
        """å°† image_dir ä¸‹æ‰€æœ‰å›¾ç‰‡è¿›è¡Œç‰¹å¾æå–"""
        if not os.path.exists(self.image_dir):
            logger.warning(f"[ImageRetrieval] âš ï¸ å›¾ç‰‡ç›®å½•ä¸å­˜åœ¨: {self.image_dir}")
            return

        self.image_paths = [
            os.path.join(self.image_dir, f)
            for f in os.listdir(self.image_dir)
            if f.lower().endswith((".png", ".jpg", ".jpeg"))
        ]

        if not self.image_paths:
            logger.warning("[ImageRetrieval] âš ï¸ æœªæ‰¾åˆ°å›¾ç‰‡ç”¨äºç´¢å¼•")
            return

        logger.info(f"[ImageRetrieval] ğŸ”¹ ç´¢å¼• {len(self.image_paths)} å¼ å›¾ç‰‡...")

        with torch.no_grad():
            for path in self.image_paths:
                try:
                    img = Image.open(path).convert("RGB")
                    img_tensor = self.preprocess(img).unsqueeze(0).to(self.device)
                    embedding = self.model.encode_image(img_tensor)
                    embedding = embedding / embedding.norm(dim=-1, keepdim=True)
                    self.image_embeddings[path] = embedding.cpu()
                except Exception as e:
                    logger.warning(f"[ImageRetrieval] âš ï¸ å›¾ç‰‡ç´¢å¼•å¤±è´¥: {path}, {e}")

        logger.info("[ImageRetrieval] âœ… å›¾ç‰‡ç´¢å¼•å®Œæˆ")

    def search(self, query: str, top_k: int = 1):
        """æ ¹æ®æ–‡æœ¬ query æ£€ç´¢å›¾ç‰‡"""
        if not self.image_embeddings:
            logger.warning("[ImageRetrieval] âš ï¸ å°šæœªæœ‰å›¾ç‰‡ç´¢å¼•ï¼Œæ— æ³•æ£€ç´¢")
            return []

        try:
            with torch.no_grad():
                text_tokens = open_clip.tokenize([query]).to(self.device)
                text_embedding = self.model.encode_text(text_tokens)
                text_embedding = text_embedding / text_embedding.norm(dim=-1, keepdim=True)

                scores = {}
                for path, img_emb in self.image_embeddings.items():
                    score = (img_emb.to(self.device) @ text_embedding.T).item()
                    scores[path] = score

                # æŒ‰ç›¸ä¼¼åº¦æ’åº
                sorted_results = sorted(scores.items(), key=lambda x: x[1], reverse=True)
                top_results = [{"image": path, "score": score} for path, score in sorted_results[:top_k]]
                logger.info(f"[ImageRetrieval] âœ… æ£€ç´¢å®Œæˆ, query='{query}', top_k={top_k}")
                return top_results

        except Exception as e:
            logger.error(f"[ImageRetrieval] âŒ æ£€ç´¢å¤±è´¥: {e}")
            return []


